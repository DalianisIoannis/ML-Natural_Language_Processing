{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ex4_SBERT.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"kQY9SwLkydRz"},"source":["# Γιάννης Δαλιάνης\n","# 1115201700027\n","# Homework 4\n","<!-- # Άσκηση 1 -->\n","\n","<!-- [Source](https://github.com/bentrevett/pytorch-sentiment-analysis) -->"]},{"cell_type":"markdown","metadata":{"id":"PSNvqFp0_cDs"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"yGaeiJ3lyPv0"},"source":["import os\n","import re\n","import pandas as pd\n","import time\n","import json\n","\n","from google.colab import drive\n","from scipy.spatial.distance import cosine\n","from ast import literal_eval\n","import torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iq50OYq02s8h"},"source":["!pip install transformers==3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oy36Iqcwd2RK"},"source":["!pip install sentence-transformers\n","from sentence_transformers import SentenceTransformer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nikl7HNbBTFr"},"source":["## A GPU can be added by going to the menu and selecting:\n","## Runtime -> Change runtime type -> Hardware accelerator: GPU"]},{"cell_type":"code","metadata":{"id":"UnsVXZyFBVaB"},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs\n","start_timeTOTAL = time.time()\n","if torch.cuda.is_available():       \n","    device = torch.device(\"cuda\")\n","    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n","    print('Device name:', torch.cuda.get_device_name(0))\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OBYBPath_g3v"},"source":["## Load Dataset"]},{"cell_type":"code","metadata":{"id":"CzXaroXcz-BD"},"source":["drive.mount('/content/gdrive', force_remount=True)\n","\n","if os.path.isfile('/content/gdrive/My Drive/dataframe.csv'):\n","  print (\"File exist\")\n","  df2 = pd.read_csv('/content/gdrive/My Drive/dataframe.csv')\n","  df2 = df2.drop(['Unnamed: 0'], axis=1)\n","else:\n","  print (\"File not exist\")\n","  num = 0\n","  \n","  totalList = list()\n","  for filename in os.listdir('/content/gdrive/My Drive/DI/Colab Notebooks/ex4/comm_use_subset/'):\n","    rowList = list()\n","    rowList.append(filename)\n","    if num%300 == 0:\n","      print(num)\n","    with open('/content/gdrive/My Drive/DI/Colab Notebooks/ex4/comm_use_subset/' + filename) as json_file:\n","        wholeText = \"\"\n","        data = json.load(json_file)\n","        \n","        article_title = data['metadata']['title']\n","        \n","        abstract = list()\n","        abstract.append(article_title)\n","        for p in data['abstract']:\n","          abstract.append(p['text'])\n","          wholeText += p['text']\n","          wholeText += \" \"\n","        \n","        body_text = list()\n","        for p in data['body_text']:\n","          body_text.append(p['text'])\n","          wholeText += p['text']\n","          wholeText += \" \"\n","        \n","        rowList.append(article_title)\n","        rowList.append(wholeText)\n","        num += 1\n","    \n","        rowList.append(article_title + \". \" + wholeText)\n","        comb = abstract + body_text\n","        \n","        rowList.append(comb)\n","\n","    totalList.append(rowList)\n","  \n","  df2 = pd.DataFrame(totalList, columns=['fileName', 'fileTitle', 'fileText', 'combinedTitle_and_Text', 'paragraphs'])\n","  df2.to_csv(r'/content/gdrive/My Drive/DI/Colab Notebooks/ex4/dataframe.csv')\n","\n","df2['fileTitle'] = df2['fileTitle'].astype(str)\n","df2['fileText'] = df2['fileText'].astype(str)\n","df2['combinedTitle_and_Text'] = df2['combinedTitle_and_Text'].astype(str)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XM_dfXbbh9TR"},"source":["## Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"HCvsFiLoBq1L"},"source":["Text preprocessing isn't essential, because we are working on scientific papers and almost every word, number etc are important for the content of the papers. Urls and special characters have been removed."]},{"cell_type":"markdown","metadata":{"id":"Kqgr7TNCH4JA"},"source":["Saves paragraphs as string instead of list so use literal_eval."]},{"cell_type":"code","metadata":{"id":"kDZem3M4h-4w"},"source":["def cleanText(text):\n","    text = text.str.replace(r'RT[\\s]+', '')                                             # Removing RT\n","    text = text.str.replace(r'#.*?(?=\\s|$)', '')                                        # remove hashtags and mentions\n","    text = text.str.replace(r'@.*?(?=\\s|$)', '')\n","    text = text.replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)  # remove urls\n","    text = text.apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n","    text = text.str.replace(r\"\\'re\", \" are\")                                            # Change 're to 'are'\n","    text = text.str.replace(r\"\\'t\", \" not\")                                             # Change 't to 'not'\n","    text = text.str.replace(r\"\\'d\", \" would\")                                           # Change 'd to 'would'\n","    text = text.replace(r'\\\\n',' ', regex=True)                                         # remove newlines and other special characters\n","    text = text.replace(r'\\\\u',' ', regex=True)\n","    text = text.replace(r'\\\\x',' ', regex=True)\n","    return text\n","\n","df2['fileTitle'] = cleanText(df2['fileTitle'])\n","df2['fileText'] = cleanText(df2['fileText'])\n","df2['combinedTitle_and_Text'] = cleanText(df2['combinedTitle_and_Text'])\n","\n","df2.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oQjD_v_iCcP1"},"source":["## Querries"]},{"cell_type":"code","metadata":{"id":"6Tokh5zSCf2W"},"source":["quers = [\n","    \"What are the coronoviruses?\",\n","    \"What was discovered in Wuhuan in December 2019?\",\n","    \"What is Coronovirus Disease 2019?\",\n","    \"What is COVID-19?\",\n","    \"What is caused by SARS-COV2?\",\n","    \"How is COVID-19 spread?\",\n","    \"Where was COVID-19 discovered?\",\n","    \"How does coronavirus spread?\"\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3jFl1Stwktal"},"source":["## Implementation description"]},{"cell_type":"markdown","metadata":{"id":"vowBr6d_k0By"},"source":["The 2 embedding technics used are doc2vec and SBert. For each one, we identify papers similar to our question based on titles only and based on titles combined with corpus as well. 'Paragraphs' column is used for returning passages that answer our querries. The QA bert model doesn't work with large corpora. "]},{"cell_type":"markdown","metadata":{"id":"qLoKucNFVZb0"},"source":["Results are better when we train our models on large text corpora, because scientific papers are very large, so they should be thoroughly examined as it comes to their similarity with the given question."]},{"cell_type":"markdown","metadata":{"id":"QRsTGNzxVTVZ"},"source":["SBert works better than doc2vec because it follows a context-dependet word embedding method which takes into account the content of the papers more clearly. SBert is also by far quicker than doc2vec. As Sbert is context-dependet, it returns more similar papers. SBert returns more suitable papers for the most of our questions. "]},{"cell_type":"markdown","metadata":{"id":"6eZ50LZAVcQ6"},"source":["When using the full corpora, we print more indicative passages to see how good our results are. Especially SBert takes into account words of the same semantic family."]},{"cell_type":"markdown","metadata":{"id":"rCTgeHYN0XjG"},"source":["## SBERT with passage finding on titles"]},{"cell_type":"markdown","metadata":{"id":"Jrl6HArurio1"},"source":["Sentence-BERT uses a Siamese network like architecture to provide 2 sentences as an input. These 2 sentences are then passed to BERT models and a pooling layer to generate their embeddings. Then use the embeddings for the pair of sentences as inputs to calculate the cosine similarity."]},{"cell_type":"markdown","metadata":{"id":"-74ae34I6HVV"},"source":["Sentence-BERT (SBERT) is inspired by the transformer model, a sequence model that dispenses of both convolutions and recurrence and uses attention instead to incorporate sequential information into sequence representation. This booming family includes BERT (and its extensions), GPT (1 and 2) and the XL-flavored transformers. These models generate contextual embeddings of input tokens (commonly sub-word units), each infused with information of its neighborhood, but are not aimed at generating a rich embedding space for input sequences. Sentence-BERT aims to adapt the BERT architecture by using siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity."]},{"cell_type":"markdown","metadata":{"id":"9LpCit746Bcv"},"source":["Passage finding is a small QA task that returns thw part from the text that answers the specific question. Some co-students suggested splitting every corpus in sentences and returning the article based on one of these questions. This would also be the passage. I didn't follow this path because it is like using the same solution for both the first and second exercise. The QA though cannot be applied on very large text and that is why the column paragraphs is used."]},{"cell_type":"markdown","metadata":{"id":"49E2EJCLBk2H"},"source":["Passages from titles only are expected to be more inaccurate."]},{"cell_type":"markdown","metadata":{"id":"LeJDSbgO0_ir"},"source":["https://www.sbert.net/examples/applications/semantic-search/README.html"]},{"cell_type":"code","metadata":{"id":"fN01s2Wa2jY7"},"source":["from transformers import BertForQuestionAnswering\n","from transformers import BertTokenizer\n","\n","modelBertQA = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n","tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yqciIKox4O7I"},"source":["def answer_question(question, answer_text):\n","    '''\n","    Takes `question` string and `answer_text` string (contains the answer).\n","    Identifies the words within the `answer_text` that are the answer.\n","    '''\n","    # ======== Tokenize ========\n","    input_ids = tokenizer.encode(question, answer_text)\n","\n","    # print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n","\n","    if len(input_ids)>512:\n","      return 0\n","\n","    # ======== Set Segment IDs ========\n","    # Search the input_ids for the first instance of the `[SEP]` token.\n","    sep_index = input_ids.index(tokenizer.sep_token_id)\n","\n","    # The number of segment A tokens includes the [SEP] token istelf.\n","    num_seg_a = sep_index + 1\n","\n","    # The remainder are segment B.\n","    num_seg_b = len(input_ids) - num_seg_a\n","\n","    # Construct the list of 0s and 1s.\n","    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n","\n","    # There should be a segment_id for every input token.\n","    assert len(segment_ids) == len(input_ids)\n","\n","    # ======== Evaluate ========\n","    # Run our example question through the model.\n","    start_scores, end_scores = modelBertQA(torch.tensor([input_ids]), # The tokens representing our input text.\n","                                    token_type_ids=torch.tensor([segment_ids]), return_dict=False) # The segment IDs to differentiate question from answer_text\n","\n","    # ======== Reconstruct Answer ========\n","    # Find the tokens with the highest `start` and `end` scores.\n","    answer_start = torch.argmax(start_scores)\n","    answer_end = torch.argmax(end_scores)\n","\n","    # Get the string versions of the input tokens.\n","    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","\n","    # Start with the first token.\n","    answer = tokens[answer_start]\n","\n","    # Select the remaining answer tokens and join them with whitespace.\n","    for i in range(answer_start + 1, answer_end + 1):\n","        \n","        # If it's a subword token, then recombine it with the previous token.\n","        if tokens[i][0:2] == '##':\n","            answer += tokens[i][2:]\n","        # Otherwise, add a space then the token.\n","        else:\n","            answer += ' ' + tokens[i]\n","\n","    if not answer.startswith(\"[CLS]\") and not answer.endswith(\"[SEP]\"):\n","        print('Passage: \"' + answer + '\"')\n","\n","    return 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IdYQO8x3rFa7"},"source":["from sentence_transformers import util\n","\n","# embedder = SentenceTransformer('bert-base-nli-mean-tokens')\n","embedder = SentenceTransformer('paraphrase-distilroberta-base-v1')\n","\n","corpus_embeddings = embedder.encode(df2['fileTitle'], convert_to_tensor=True)\n","corpus_embeddings = corpus_embeddings.to('cuda')\n","\n","# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n","top_k = min(5, len(df2['fileTitle']))\n","for query in quers:\n","    \n","    query_embedding = embedder.encode(query, convert_to_tensor=True)\n","    query_embedding = query_embedding.to('cuda')\n","\n","    print(\"\\n\\n======================\\n\\n\")\n","    print(\"Query:\", query)\n","    print(\"\\nTop 5 most similar titles:\")\n","\n","    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=top_k)\n","\n","    for i in hits[0]:\n","      print( \"  \", df2['fileTitle'].iloc[i['corpus_id']], \"(Score: {:.4f})\".format(i['score']) )\n","\n","    answer_question(query, df2['fileTitle'].iloc[ hits[0][0]['corpus_id'] ])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"noKevgv7nOqK"},"source":["## SBERT with passage finding on combined titles and corpus"]},{"cell_type":"code","metadata":{"id":"TMp8RDDrnOqL"},"source":["modelBertQA = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n","tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P3yZfLDUiB8i"},"source":["Also returns the more suitable passage(if exists) from every paper paragraph."]},{"cell_type":"code","metadata":{"id":"mWTdVIIUnOqM"},"source":["# embedder = SentenceTransformer('bert-base-nli-mean-tokens')\n","embedder = SentenceTransformer('paraphrase-distilroberta-base-v1')\n","\n","corpus_embeddings = embedder.encode(df2['combinedTitle_and_Text'], convert_to_tensor=True)\n","corpus_embeddings = corpus_embeddings.to('cuda')\n","\n","# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n","top_k = min(5, len(df2['combinedTitle_and_Text']))\n","for query in quers:\n","    \n","    query_embedding = embedder.encode(query, convert_to_tensor=True)\n","    query_embedding = query_embedding.to('cuda')\n","\n","    print(\"\\n\\n======================\\n\\n\")\n","    print(\"Query:\", query)\n","    print(\"\\nTop 5 most similar text:\")\n","\n","    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=top_k)\n","\n","    for i in hits[0]:\n","      print( \"  \", df2['combinedTitle_and_Text'].iloc[i['corpus_id']], \"(Score: {:.4f})\".format(i['score']) )\n","      \n","    print(\"\\nFor more similar text:\")\n","    \n","    for i in literal_eval(df2['paragraphs'].iloc[ hits[0][0]['corpus_id'] ]):\n","      if answer_question(query, i)==0:\n","        firstpart, secondpart = i[:int(int(len(i))/2)], i[int(int(len(i))/2):]\n","        answer_question(query, firstpart)\n","        answer_question(query, secondpart)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JS6-V6G_XgRW"},"source":["We see how often the passages are similar to the questions."]},{"cell_type":"markdown","metadata":{"id":"ErTc9OzqGS44"},"source":["## Time Needed"]},{"cell_type":"code","metadata":{"id":"VvmffkXsUJsx"},"source":["end_timeTOTAL = time.time()\n","mins, secs = epoch_time(start_timeTOTAL, end_timeTOTAL)\n","print(f'Total Time: {mins}m {secs}s')"],"execution_count":null,"outputs":[]}]}